<!DOCTYPE html>
<html>
<head>
    
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Understanding Gradient Descent &#8211; Page 42</title>
    <link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com">
    <link rel="dns-prefetch" href="//cdn.mathjax.org">
    <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="A simple, beautiful theme for Jekyll that emphasizes content rather than aesthetic fluff.">
    <meta name="robots" content="all">
    <meta name="author" content="Abhinav Choudhury">
    
    <meta name="keywords" content="jekyll, update">
    <link rel="canonical" href="http://localhost:4000/jekyll/update/2017/04/15/gradient-descent/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Page 42" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201704160125" type="text/css">

    <!-- Fonts -->
    
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- MathJax -->
    
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    

    <!-- Verifications -->
    
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Understanding Gradient Descent">
    <meta property="og:description" content="A simple, beautiful theme for Jekyll that emphasizes content rather than aesthetic fluff.">
    <meta property="og:url" content="http://localhost:4000/jekyll/update/2017/04/15/gradient-descent/">
    <meta property="og:site_name" content="Page 42">
    

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
    <meta name="twitter:title" content="Understanding Gradient Descent" />
    <meta name="twitter:description" content="A simple, beautiful theme for Jekyll that emphasizes content rather than aesthetic fluff." />
    <meta name="twitter:url" content="http://localhost:4000/jekyll/update/2017/04/15/gradient-descent/" />
    

    <!-- Icons -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">

    
</head>

<body class="site">
  
	

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="http://localhost:4000" class="site-title">Page 42</a>
      <nav class="site-nav">
        
    

    
        <a href="/about/">About</a>
    

    

    

    

    

    

    

    

    


    

    

    

    

    

    

    

    

    

    


      </nav>
      <div class="clearfix"></div>
      
        <div class="social-icons">
  <div class="social-icons-right">
    
      <a class="fa fa-github" href="https://github.com/abhinavchdhry"></a>
    
    
    
    <a class="fa fa-rss" href="/feed.xml"></a>
    
    
    
    
    
      <a class="fa fa-envelope" href="mailto:achoudh3@ncsu.edu"></a>
    
    
    
    
    
    
  </div>
  <div class="right">
    
    
    
  </div>
</div>
<div class="clearfix"></div>

      
	
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
	


<div class="post-header mb2">
  <h1>Understanding Gradient Descent</h1>
  <span class="post-meta">Apr 15, 2017</span><br>
  
  <span class="post-meta small">
  
    3 minute read
  
  </span>
</div>

<article class="post-content">
  <h3 id="the-problem-statement">The Problem statement</h3>
<p>Given a function <script type="math/tex">f : X \rightarrow R</script> where <script type="math/tex">X = (x_1, x_2, ... x_n)</script> is a n-dimensional vector, find a minima <script type="math/tex">X^*</script> equation (a point for which <script type="math/tex">f(X^*)</script> is a minimum)</p>

<h3 id="2-dimensional-case">2 dimensional case</h3>
<p>For the sake of simplicity and notation, we will first consider the case when the vector X is in 2-dimensional space i.e. <script type="math/tex">X = (x_1, x_2)</script>. The graph for this function might look something like this (this one happens to be a plot of <script type="math/tex">z = sin(x) + sin(y)</script>)</p>

<p>[Image]</p>

<p>Imagine now that this graph represents the some part of surface of the earth and you happen to be standing at some point in it. Your goal is head to the deepest point possible (in other words, head to the point with the lowest elevation).</p>

<p>The first thing you’re probably going to think of (without even being aware of it) is this: which direction do I take the next step? Of course you won’t take a step uphill from that point. Simple logic tells us to head downwards along the direction of steepest decline (assuming of course that you don’t slip and fall). This is the exact thinking behind the gradient descent algorithm: <strong>find the direction of maximum increasing (positive) gradient at the current point and take a small step in the opposite direction.</strong></p>

<p>Now, by the rules of calculus, a small change in the function <script type="math/tex">\Delta f</script> due to a small change in the vector <script type="math/tex">\Delta X = (\Delta x_1, \Delta x_2)</script> is given by:</p>

<script type="math/tex; mode=display">\Delta f = \frac{\partial f}{\partial x_1}.\Delta x_1 + \frac{\partial f}{\partial x_2}.\Delta x_2</script>

<p>or, in vector notation</p>

<script type="math/tex; mode=display">\Delta f = \nabla f . \Delta X,  
	where \nabla f = (\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2})</script>

<p>Our goal now is to choose the delta vector <script type="math/tex">\Delta X = (\Delta x_1, \Delta x_2)</script> so as to make sure that:</p>
<ul>
  <li>The value <script type="math/tex">\Delta f</script> is negative (so that we know we are moving in the direction of decreasing gradient, or downwards)</li>
  <li>The magnitude of <script type="math/tex">\Delta f</script> is maximum along this direction</li>
</ul>

<p>If we choose <script type="math/tex">\Delta f</script> as follows: <script type="math/tex">\Delta X = -\eta.\nabla f</script>, then</p>

<script type="math/tex; mode=display">\Delta f = \mathbf{\nabla f}.(-\eta \mathbf{\nabla f}) = -\eta.(\mathbf{\nabla f.\nabla f}) = -\eta.(positive value) = negative</script>

<p><br />
<strong>The delta vector is now parallel to the gradient vector at that point</strong> which according to the Cauchy-Schwartz inequality maximizes the magnitude of the dot product of the 2 vectors (hence maximizing <script type="math/tex">\left \| \Delta f \right \|</script> ). Note that the positive constant <script type="math/tex">\eta</script>  does not change the direction of the vector, only scales its value. Since we are only looking to find the direction of maximization of descent, scaling the vector does not affect our goal.</p>

<p><script type="math/tex">\eta</script> is also called the <strong>learning rate</strong>, a value that determines how large or small a step we take while descending. <script type="math/tex">\eta</script> should be small so as not to introduce error (if the step is too large, we might miss the minima). Also it should not be too small that the descent takes a long time.</p>

<p>And so we arrive at the update function for the variable vector X:</p>

<script type="math/tex; mode=display">\mathbf{X_{new}} = \mathbf{X_{old}} - \eta.\mathbf{\nabla f}</script>

<p>Although we have described the problem for the special case of 2 dimensions, it easily extends to the more general case of N dimensions. The formula above remains the same.
<br /></p>
<h3 id="iterations-and-when-to-stop-todo">Iterations and when to stop (TODO)</h3>

<p><br /></p>
<h3 id="drawbacks">Drawbacks</h3>
<p>Note that, in general, a function can have multiple local minima and a global minima. Based on how the gradient descent algorithm is initialized (the initial value that we choose for the variable vector) and the structure of the function itself, we may end up at any one of these local minima. <strong>So gradient descent does not always result in the global minima</strong>.</p>

<p><br /></p>
<h3 id="proof-todo">Proof (TODO)</h3>
<p>According to the <a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Cauchy-Schwartz inequality</a> for any 2 vectors <script type="math/tex">\mathbf{u}</script> and<script type="math/tex">\mathbf{v}</script> of the same size, <script type="math/tex">\| \mathbf{u}.\mathbf{v} \| \le \| \mathbf{u} \| . \| \mathbf{v} \|</script> and the equality happens when u and v are equal.</p>

<p>If we restrict our change vector <script type="math/tex">\Delta X</script> (or the incremental step) to be small, as restricted by <script type="math/tex">\| \Delta X \| \le \epsilon</script>for some small <script type="math/tex">\epsilon > 0</script> then according to the Cauchy-Schwartz inequality, the magnitude of change is</p>

<script type="math/tex; mode=display">| \Delta f | = | \mathbf{\nabla f }. \mathbf{\Delta X} |  \le | \mathbf{\nabla f} |.| \mathbf{\Delta X}| \le |\mathbf{\nabla f}|.\epsilon</script>


</article>











      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
	Page 42 is a blog about making machines learn.
    </small>
  </div>
</footer>


</body>
</html>
